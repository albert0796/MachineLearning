{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Flatten, Dense, Dropout, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.models import load_model\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "net = keras.applications.densenet.DenseNet121(include_top=False, weights='imagenet', input_tensor=None, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = net.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(128)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output_layer = Dense(20, activation='softmax', name='softmax')(x)\n",
    "net_final = Model(inputs=net.input, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for layer in net_final.layers:\n",
    "    count+=1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalization)         (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 50176)        0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          6422656     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 20)           2580        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,462,740\n",
      "Trainable params: 13,379,092\n",
      "Non-trainable params: 83,648\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(net_final.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"\"\\n# \\nfor layer in net_final.layers[:-5]:\\n    layer.trainable = False\\nfor layer in net_final.layers[-5:]:\\n    layer.trainable = True\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\"\"\n",
    "# \n",
    "for layer in net_final.layers[:-5]:\n",
    "    layer.trainable = False\n",
    "for layer in net_final.layers[-5:]:\n",
    "    layer.trainable = True\n",
    "\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for layer in net_final.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_final.compile(Adam(lr=.00002122), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = np.load(\"C:/Users/firzen41616316/Desktop/numpydataKeras_20_val/imgonehot_val_1000.npy\")\n",
    "V2 = np.load(\"C:/Users/firzen41616316/Desktop/numpydataKeras_20_val/labelonehot_val_1000.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 103s 103ms/step - loss: 4.2355 - acc: 0.0770 - val_loss: 2.9334 - val_acc: 0.1430\n",
      "Done training  1000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 3.1707 - acc: 0.1440 - val_loss: 2.5808 - val_acc: 0.2210\n",
      "Done training  2000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.8926 - acc: 0.1560 - val_loss: 2.3693 - val_acc: 0.2770\n",
      "Done training  3000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.7279 - acc: 0.2000 - val_loss: 2.2116 - val_acc: 0.3380\n",
      "Done training  4000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.4879 - acc: 0.2350 - val_loss: 2.0858 - val_acc: 0.3670\n",
      "Done training  5000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 2.3866 - acc: 0.2720 - val_loss: 1.9664 - val_acc: 0.3880\n",
      "Done training  6000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.2575 - acc: 0.3210 - val_loss: 1.8402 - val_acc: 0.4340\n",
      "Done training  7000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.2665 - acc: 0.2980 - val_loss: 1.7596 - val_acc: 0.4600\n",
      "Done training  8000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.1464 - acc: 0.3400 - val_loss: 1.6764 - val_acc: 0.4850\n",
      "Done training  9000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.1589 - acc: 0.3330 - val_loss: 1.6113 - val_acc: 0.5120\n",
      "Done training  10000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.0195 - acc: 0.3760 - val_loss: 1.5568 - val_acc: 0.5170\n",
      "Done training  11000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 2.0112 - acc: 0.3760 - val_loss: 1.5242 - val_acc: 0.5300\n",
      "Done training  12000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.9216 - acc: 0.4200 - val_loss: 1.4918 - val_acc: 0.5560\n",
      "Done training  13000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.9345 - acc: 0.4180 - val_loss: 1.4618 - val_acc: 0.5670\n",
      "Done training  14000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.8933 - acc: 0.4260 - val_loss: 1.4327 - val_acc: 0.5660\n",
      "Done training  15000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.8415 - acc: 0.4280 - val_loss: 1.4148 - val_acc: 0.5760\n",
      "Done training  16000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.8316 - acc: 0.4400 - val_loss: 1.3826 - val_acc: 0.5830\n",
      "Done training  17000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.7995 - acc: 0.4670 - val_loss: 1.3625 - val_acc: 0.5970\n",
      "Done training  18000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.7264 - acc: 0.4830 - val_loss: 1.3413 - val_acc: 0.5930\n",
      "Done training  19000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.8896 - acc: 0.4400 - val_loss: 1.3456 - val_acc: 0.6000\n",
      "Done training  20000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.8885 - acc: 0.4560 - val_loss: 1.3444 - val_acc: 0.6110\n",
      "Done training  21000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.7671 - acc: 0.4590 - val_loss: 1.2955 - val_acc: 0.6240\n",
      "Done training  22000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.7716 - acc: 0.5000 - val_loss: 1.2743 - val_acc: 0.6220\n",
      "Done training  23000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.6630 - acc: 0.5080 - val_loss: 1.2605 - val_acc: 0.6280\n",
      "Done training  24000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.7659 - acc: 0.4730 - val_loss: 1.2773 - val_acc: 0.6130\n",
      "Done training  25000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.6651 - acc: 0.4850 - val_loss: 1.2753 - val_acc: 0.6160\n",
      "Done training  26000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.6894 - acc: 0.4870 - val_loss: 1.2748 - val_acc: 0.6110\n",
      "Done training  27000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.7730 - acc: 0.4740 - val_loss: 1.2497 - val_acc: 0.6280\n",
      "Done training  28000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.7744 - acc: 0.4740 - val_loss: 1.2364 - val_acc: 0.6320\n",
      "Done training  29000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.6698 - acc: 0.5090 - val_loss: 1.2299 - val_acc: 0.6330\n",
      "Done training  30000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6953 - acc: 0.4890 - val_loss: 1.2187 - val_acc: 0.6270\n",
      "Done training  31000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.6851 - acc: 0.4920 - val_loss: 1.2107 - val_acc: 0.6430\n",
      "Done training  32000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5774 - acc: 0.5170 - val_loss: 1.1919 - val_acc: 0.6380\n",
      "Done training  33000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6789 - acc: 0.5130 - val_loss: 1.1929 - val_acc: 0.6510\n",
      "Done training  34000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6086 - acc: 0.5200 - val_loss: 1.1985 - val_acc: 0.6480\n",
      "Done training  35000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6029 - acc: 0.5090 - val_loss: 1.1856 - val_acc: 0.6500\n",
      "Done training  36000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.6534 - acc: 0.5070 - val_loss: 1.1908 - val_acc: 0.6410\n",
      "Done training  37000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6641 - acc: 0.5080 - val_loss: 1.2034 - val_acc: 0.6450\n",
      "Done training  38000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.6655 - acc: 0.5130 - val_loss: 1.1933 - val_acc: 0.6400\n",
      "Done training  39000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6190 - acc: 0.5160 - val_loss: 1.1709 - val_acc: 0.6410\n",
      "Done training  40000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5007 - acc: 0.5540 - val_loss: 1.1605 - val_acc: 0.6520\n",
      "Done training  41000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5880 - acc: 0.5440 - val_loss: 1.1647 - val_acc: 0.6550\n",
      "Done training  42000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4981 - acc: 0.5530 - val_loss: 1.1445 - val_acc: 0.6530\n",
      "Done training  43000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4996 - acc: 0.5490 - val_loss: 1.1321 - val_acc: 0.6550\n",
      "Done training  44000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5077 - acc: 0.5460 - val_loss: 1.1336 - val_acc: 0.6550\n",
      "Done training  45000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4738 - acc: 0.5500 - val_loss: 1.1399 - val_acc: 0.6530\n",
      "Done training  46000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.4933 - acc: 0.5510 - val_loss: 1.1368 - val_acc: 0.6460\n",
      "Done training  47000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.6711 - acc: 0.5240 - val_loss: 1.1176 - val_acc: 0.6570\n",
      "Done training  48000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4959 - acc: 0.5480 - val_loss: 1.1434 - val_acc: 0.6570\n",
      "Done training  49000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5069 - acc: 0.5540 - val_loss: 1.1424 - val_acc: 0.6470\n",
      "Done training  50000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4150 - acc: 0.5600 - val_loss: 1.1270 - val_acc: 0.6550\n",
      "Done training  51000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.5589 - acc: 0.5560 - val_loss: 1.1091 - val_acc: 0.6600\n",
      "Done training  52000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5155 - acc: 0.5450 - val_loss: 1.1152 - val_acc: 0.6540\n",
      "Done training  53000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4670 - acc: 0.5640 - val_loss: 1.1082 - val_acc: 0.6550\n",
      "Done training  54000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.4819 - acc: 0.5590 - val_loss: 1.1142 - val_acc: 0.6540\n",
      "Done training  55000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5093 - acc: 0.5580 - val_loss: 1.1130 - val_acc: 0.6560\n",
      "Done training  56000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5299 - acc: 0.5620 - val_loss: 1.1048 - val_acc: 0.6610\n",
      "Done training  57000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5636 - acc: 0.5450 - val_loss: 1.0993 - val_acc: 0.6730\n",
      "Done training  58000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4919 - acc: 0.5520 - val_loss: 1.0981 - val_acc: 0.6600\n",
      "Done training  59000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4723 - acc: 0.5580 - val_loss: 1.0888 - val_acc: 0.6590\n",
      "Done training  60000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.5346 - acc: 0.5470 - val_loss: 1.0775 - val_acc: 0.6740\n",
      "Done training  61000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.5584 - acc: 0.5320 - val_loss: 1.0807 - val_acc: 0.6640\n",
      "Done training  62000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.4304 - acc: 0.5740 - val_loss: 1.0716 - val_acc: 0.6670\n",
      "Done training  63000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.5641 - acc: 0.5530 - val_loss: 1.0543 - val_acc: 0.6690\n",
      "Done training  64000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.4358 - acc: 0.5720 - val_loss: 1.0536 - val_acc: 0.6680\n",
      "Done training  65000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.4989 - acc: 0.5650 - val_loss: 1.0509 - val_acc: 0.6650\n",
      "Done training  66000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.4502 - acc: 0.5750 - val_loss: 1.0485 - val_acc: 0.6730\n",
      "Done training  67000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.4840 - acc: 0.5660 - val_loss: 1.0466 - val_acc: 0.6740\n",
      "Done training  68000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 42s 42ms/step - loss: 1.4857 - acc: 0.5600 - val_loss: 1.0586 - val_acc: 0.6590\n",
      "Done training  69000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.4588 - acc: 0.5560 - val_loss: 1.0541 - val_acc: 0.6760\n",
      "Done training  70000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.4617 - acc: 0.5740 - val_loss: 1.0383 - val_acc: 0.6650\n",
      "Done training  71000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.5442 - acc: 0.5670 - val_loss: 1.0405 - val_acc: 0.6680\n",
      "Done training  72000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.4805 - acc: 0.5770 - val_loss: 1.0418 - val_acc: 0.6790\n",
      "Done training  73000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.5317 - acc: 0.5570 - val_loss: 1.0586 - val_acc: 0.6710\n",
      "Done training  74000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.4370 - acc: 0.5600 - val_loss: 1.0429 - val_acc: 0.6820\n",
      "Done training  75000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.5378 - acc: 0.5440 - val_loss: 1.0544 - val_acc: 0.6720\n",
      "Done training  76000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4471 - acc: 0.5720 - val_loss: 1.0402 - val_acc: 0.6670\n",
      "Done training  77000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3202 - acc: 0.6130 - val_loss: 1.0311 - val_acc: 0.6690\n",
      "Done training  78000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4698 - acc: 0.5820 - val_loss: 1.0415 - val_acc: 0.6730\n",
      "Done training  79000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.4055 - acc: 0.5850 - val_loss: 1.0456 - val_acc: 0.6720\n",
      "Done training  80000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.4114 - acc: 0.5840 - val_loss: 1.0411 - val_acc: 0.6750\n",
      "Done training  81000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4038 - acc: 0.5810 - val_loss: 1.0539 - val_acc: 0.6830\n",
      "Done training  82000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4952 - acc: 0.5560 - val_loss: 1.0677 - val_acc: 0.6640\n",
      "Done training  83000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4075 - acc: 0.5810 - val_loss: 1.0552 - val_acc: 0.6750\n",
      "Done training  84000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3969 - acc: 0.6080 - val_loss: 1.0468 - val_acc: 0.6720\n",
      "Done training  85000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3389 - acc: 0.5840 - val_loss: 1.0556 - val_acc: 0.6770\n",
      "Done training  86000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4788 - acc: 0.5650 - val_loss: 1.0351 - val_acc: 0.6850\n",
      "Done training  87000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3316 - acc: 0.5980 - val_loss: 1.0332 - val_acc: 0.6780\n",
      "Done training  88000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4342 - acc: 0.5610 - val_loss: 1.0154 - val_acc: 0.6660\n",
      "Done training  89000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.4015 - acc: 0.5940 - val_loss: 1.0171 - val_acc: 0.6730\n",
      "Done training  90000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3945 - acc: 0.5840 - val_loss: 1.0268 - val_acc: 0.6790\n",
      "Done training  91000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3966 - acc: 0.5890 - val_loss: 1.0267 - val_acc: 0.6710\n",
      "Done training  92000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3813 - acc: 0.5980 - val_loss: 1.0271 - val_acc: 0.6730\n",
      "Done training  93000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3138 - acc: 0.6220 - val_loss: 1.0390 - val_acc: 0.6610\n",
      "Done training  94000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2481 - acc: 0.6180 - val_loss: 1.0353 - val_acc: 0.6630\n",
      "Done training  95000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3399 - acc: 0.6060 - val_loss: 1.0315 - val_acc: 0.6670\n",
      "Done training  96000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3776 - acc: 0.6060 - val_loss: 1.0348 - val_acc: 0.6740\n",
      "Done training  97000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3664 - acc: 0.5870 - val_loss: 1.0389 - val_acc: 0.6690\n",
      "Done training  98000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.3271 - acc: 0.6080 - val_loss: 1.0319 - val_acc: 0.6620\n",
      "Done training  99000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3828 - acc: 0.5880 - val_loss: 1.0369 - val_acc: 0.6680\n",
      "Done training  100000  images in Epoch :  0\n",
      "Done training 100000 images, Epoch  0   -------------\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3404 - acc: 0.5800 - val_loss: 1.0389 - val_acc: 0.6560\n",
      "Done training  1000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.3489 - acc: 0.5950 - val_loss: 1.0327 - val_acc: 0.6710\n",
      "Done training  2000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3361 - acc: 0.6080 - val_loss: 1.0398 - val_acc: 0.6690\n",
      "Done training  3000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3739 - acc: 0.5800 - val_loss: 1.0452 - val_acc: 0.6690\n",
      "Done training  4000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3323 - acc: 0.6070 - val_loss: 1.0364 - val_acc: 0.6590\n",
      "Done training  5000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3139 - acc: 0.6230 - val_loss: 1.0333 - val_acc: 0.6660\n",
      "Done training  6000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2726 - acc: 0.6110 - val_loss: 1.0245 - val_acc: 0.6690\n",
      "Done training  7000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3896 - acc: 0.5850 - val_loss: 1.0099 - val_acc: 0.6870\n",
      "Done training  8000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2730 - acc: 0.6230 - val_loss: 1.0146 - val_acc: 0.6800\n",
      "Done training  9000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3113 - acc: 0.6210 - val_loss: 1.0288 - val_acc: 0.6780\n",
      "Done training  10000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3310 - acc: 0.5960 - val_loss: 1.0094 - val_acc: 0.6850\n",
      "Done training  11000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3508 - acc: 0.6040 - val_loss: 1.0035 - val_acc: 0.6890\n",
      "Done training  12000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2764 - acc: 0.6100 - val_loss: 1.0294 - val_acc: 0.6840\n",
      "Done training  13000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.3185 - acc: 0.6010 - val_loss: 1.0267 - val_acc: 0.6830\n",
      "Done training  14000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2927 - acc: 0.6120 - val_loss: 1.0138 - val_acc: 0.6850\n",
      "Done training  15000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2574 - acc: 0.6180 - val_loss: 1.0148 - val_acc: 0.6810\n",
      "Done training  16000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2599 - acc: 0.6380 - val_loss: 1.0164 - val_acc: 0.6980\n",
      "Done training  17000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2408 - acc: 0.6360 - val_loss: 1.0187 - val_acc: 0.6950\n",
      "Done training  18000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.2241 - acc: 0.6360 - val_loss: 1.0087 - val_acc: 0.6950\n",
      "Done training  19000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.2155 - acc: 0.6320 - val_loss: 1.0023 - val_acc: 0.6940\n",
      "Done training  20000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2607 - acc: 0.6260 - val_loss: 1.0080 - val_acc: 0.6860\n",
      "Done training  21000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.3358 - acc: 0.6080 - val_loss: 1.0074 - val_acc: 0.6910\n",
      "Done training  22000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2648 - acc: 0.6070 - val_loss: 1.0026 - val_acc: 0.6920\n",
      "Done training  23000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.2538 - acc: 0.6280 - val_loss: 1.0023 - val_acc: 0.6760\n",
      "Done training  24000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2451 - acc: 0.6230 - val_loss: 1.0023 - val_acc: 0.6730\n",
      "Done training  25000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.2698 - acc: 0.6170 - val_loss: 1.0022 - val_acc: 0.6760\n",
      "Done training  26000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2982 - acc: 0.6120 - val_loss: 1.0063 - val_acc: 0.6790\n",
      "Done training  27000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.3152 - acc: 0.5940 - val_loss: 1.0065 - val_acc: 0.6750\n",
      "Done training  28000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2837 - acc: 0.6050 - val_loss: 1.0080 - val_acc: 0.6830\n",
      "Done training  29000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1965 - acc: 0.6210 - val_loss: 1.0046 - val_acc: 0.6920\n",
      "Done training  30000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.3328 - acc: 0.6060 - val_loss: 1.0086 - val_acc: 0.6790\n",
      "Done training  31000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2682 - acc: 0.6190 - val_loss: 1.0082 - val_acc: 0.6750\n",
      "Done training  32000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1912 - acc: 0.6360 - val_loss: 1.0031 - val_acc: 0.6850\n",
      "Done training  33000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2572 - acc: 0.6240 - val_loss: 1.0091 - val_acc: 0.6860\n",
      "Done training  34000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2977 - acc: 0.6110 - val_loss: 1.0335 - val_acc: 0.6760\n",
      "Done training  35000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2736 - acc: 0.6110 - val_loss: 1.0179 - val_acc: 0.6810\n",
      "Done training  36000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2893 - acc: 0.6130 - val_loss: 1.0103 - val_acc: 0.6780\n",
      "Done training  37000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2445 - acc: 0.6260 - val_loss: 1.0222 - val_acc: 0.6740\n",
      "Done training  38000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.3293 - acc: 0.6020 - val_loss: 0.9997 - val_acc: 0.6910\n",
      "Done training  39000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1769 - acc: 0.6470 - val_loss: 0.9903 - val_acc: 0.6970\n",
      "Done training  40000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2147 - acc: 0.6320 - val_loss: 0.9805 - val_acc: 0.6940\n",
      "Done training  41000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2021 - acc: 0.6460 - val_loss: 1.0030 - val_acc: 0.6990\n",
      "Done training  42000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1585 - acc: 0.6330 - val_loss: 1.0165 - val_acc: 0.6870\n",
      "Done training  43000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1411 - acc: 0.6510 - val_loss: 0.9898 - val_acc: 0.6950\n",
      "Done training  44000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2241 - acc: 0.6380 - val_loss: 1.0180 - val_acc: 0.6930\n",
      "Done training  45000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2011 - acc: 0.6500 - val_loss: 1.0185 - val_acc: 0.6930\n",
      "Done training  46000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2104 - acc: 0.6570 - val_loss: 1.0087 - val_acc: 0.6880\n",
      "Done training  47000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2757 - acc: 0.6130 - val_loss: 1.0093 - val_acc: 0.6800\n",
      "Done training  48000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1814 - acc: 0.6240 - val_loss: 1.0053 - val_acc: 0.6840\n",
      "Done training  49000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1708 - acc: 0.6320 - val_loss: 1.0074 - val_acc: 0.6790\n",
      "Done training  50000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2378 - acc: 0.6450 - val_loss: 0.9988 - val_acc: 0.6940\n",
      "Done training  51000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2769 - acc: 0.6230 - val_loss: 0.9902 - val_acc: 0.6940\n",
      "Done training  52000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1476 - acc: 0.6680 - val_loss: 0.9850 - val_acc: 0.6990\n",
      "Done training  53000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1690 - acc: 0.6520 - val_loss: 0.9880 - val_acc: 0.6960\n",
      "Done training  54000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2702 - acc: 0.6330 - val_loss: 0.9871 - val_acc: 0.6880\n",
      "Done training  55000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1205 - acc: 0.6660 - val_loss: 0.9860 - val_acc: 0.6920\n",
      "Done training  56000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1665 - acc: 0.6390 - val_loss: 0.9953 - val_acc: 0.6940\n",
      "Done training  57000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2557 - acc: 0.6220 - val_loss: 0.9880 - val_acc: 0.7010\n",
      "Done training  58000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2333 - acc: 0.6250 - val_loss: 0.9748 - val_acc: 0.7040\n",
      "Done training  59000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1320 - acc: 0.6430 - val_loss: 0.9761 - val_acc: 0.6940\n",
      "Done training  60000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2073 - acc: 0.6200 - val_loss: 0.9799 - val_acc: 0.6880\n",
      "Done training  61000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2451 - acc: 0.6320 - val_loss: 0.9673 - val_acc: 0.6870\n",
      "Done training  62000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1516 - acc: 0.6500 - val_loss: 0.9683 - val_acc: 0.6850\n",
      "Done training  63000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2901 - acc: 0.6200 - val_loss: 0.9638 - val_acc: 0.6930\n",
      "Done training  64000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1587 - acc: 0.6550 - val_loss: 0.9635 - val_acc: 0.6880\n",
      "Done training  65000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1477 - acc: 0.6350 - val_loss: 0.9577 - val_acc: 0.6970\n",
      "Done training  66000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1612 - acc: 0.6390 - val_loss: 0.9441 - val_acc: 0.7040\n",
      "Done training  67000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2565 - acc: 0.6340 - val_loss: 0.9391 - val_acc: 0.7000\n",
      "Done training  68000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2135 - acc: 0.6420 - val_loss: 0.9503 - val_acc: 0.6980\n",
      "Done training  69000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1606 - acc: 0.6380 - val_loss: 0.9577 - val_acc: 0.6940\n",
      "Done training  70000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1732 - acc: 0.6500 - val_loss: 0.9530 - val_acc: 0.7050\n",
      "Done training  71000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1796 - acc: 0.6570 - val_loss: 0.9613 - val_acc: 0.7030\n",
      "Done training  72000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2039 - acc: 0.6280 - val_loss: 0.9574 - val_acc: 0.6950\n",
      "Done training  73000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1658 - acc: 0.6550 - val_loss: 0.9575 - val_acc: 0.6990\n",
      "Done training  74000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1920 - acc: 0.6340 - val_loss: 0.9255 - val_acc: 0.7100\n",
      "Done training  75000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.1908 - acc: 0.6250 - val_loss: 0.9229 - val_acc: 0.7130\n",
      "Done training  76000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.2146 - acc: 0.6370 - val_loss: 0.9431 - val_acc: 0.6990\n",
      "Done training  77000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.1095 - acc: 0.6590 - val_loss: 0.9369 - val_acc: 0.7070\n",
      "Done training  78000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.2082 - acc: 0.6250 - val_loss: 0.9409 - val_acc: 0.7050\n",
      "Done training  79000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.1178 - acc: 0.6570 - val_loss: 0.9739 - val_acc: 0.6860\n",
      "Done training  80000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.1124 - acc: 0.6740 - val_loss: 0.9583 - val_acc: 0.6910\n",
      "Done training  81000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 1.2236 - acc: 0.6340 - val_loss: 0.9591 - val_acc: 0.6950\n",
      "Done training  82000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.1707 - acc: 0.6520 - val_loss: 0.9591 - val_acc: 0.6840\n",
      "Done training  83000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.1451 - acc: 0.6600 - val_loss: 0.9560 - val_acc: 0.6900\n",
      "Done training  84000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0833 - acc: 0.6320 - val_loss: 0.9605 - val_acc: 0.6990\n",
      "Done training  85000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1571 - acc: 0.6540 - val_loss: 0.9660 - val_acc: 0.6910\n",
      "Done training  86000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2011 - acc: 0.6240 - val_loss: 0.9529 - val_acc: 0.7010\n",
      "Done training  87000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1393 - acc: 0.6510 - val_loss: 0.9421 - val_acc: 0.6980\n",
      "Done training  88000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1131 - acc: 0.6350 - val_loss: 0.9528 - val_acc: 0.7020\n",
      "Done training  89000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1479 - acc: 0.6480 - val_loss: 0.9699 - val_acc: 0.6970\n",
      "Done training  90000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1917 - acc: 0.6290 - val_loss: 0.9477 - val_acc: 0.7070\n",
      "Done training  91000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1739 - acc: 0.6450 - val_loss: 0.9666 - val_acc: 0.7060\n",
      "Done training  92000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1485 - acc: 0.6530 - val_loss: 0.9679 - val_acc: 0.6950\n",
      "Done training  93000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1012 - acc: 0.6690 - val_loss: 0.9724 - val_acc: 0.6950\n",
      "Done training  94000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1511 - acc: 0.6470 - val_loss: 0.9701 - val_acc: 0.6990\n",
      "Done training  95000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1133 - acc: 0.6740 - val_loss: 0.9616 - val_acc: 0.6950\n",
      "Done training  96000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0882 - acc: 0.6750 - val_loss: 0.9581 - val_acc: 0.6930\n",
      "Done training  97000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0920 - acc: 0.6680 - val_loss: 0.9786 - val_acc: 0.6870\n",
      "Done training  98000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1532 - acc: 0.6340 - val_loss: 0.9890 - val_acc: 0.6810\n",
      "Done training  99000  images in Epoch :  1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2075 - acc: 0.6430 - val_loss: 0.9710 - val_acc: 0.6830\n",
      "Done training  100000  images in Epoch :  1\n",
      "Done training 100000 images, Epoch  1   -------------\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1222 - acc: 0.6610 - val_loss: 0.9669 - val_acc: 0.6950\n",
      "Done training  1000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1543 - acc: 0.6440 - val_loss: 0.9695 - val_acc: 0.6990\n",
      "Done training  2000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1104 - acc: 0.6650 - val_loss: 0.9651 - val_acc: 0.7020\n",
      "Done training  3000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1309 - acc: 0.6490 - val_loss: 0.9825 - val_acc: 0.6980\n",
      "Done training  4000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1234 - acc: 0.6470 - val_loss: 0.9847 - val_acc: 0.7030\n",
      "Done training  5000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1208 - acc: 0.6690 - val_loss: 0.9717 - val_acc: 0.6910\n",
      "Done training  6000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0378 - acc: 0.6820 - val_loss: 0.9599 - val_acc: 0.7010\n",
      "Done training  7000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.2458 - acc: 0.6320 - val_loss: 0.9412 - val_acc: 0.7160\n",
      "Done training  8000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1986 - acc: 0.6550 - val_loss: 0.9342 - val_acc: 0.7120\n",
      "Done training  9000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1331 - acc: 0.6560 - val_loss: 0.9541 - val_acc: 0.7080\n",
      "Done training  10000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1303 - acc: 0.6550 - val_loss: 0.9577 - val_acc: 0.7030\n",
      "Done training  11000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1157 - acc: 0.6640 - val_loss: 0.9596 - val_acc: 0.7020\n",
      "Done training  12000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1031 - acc: 0.6640 - val_loss: 0.9767 - val_acc: 0.6830\n",
      "Done training  13000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0790 - acc: 0.6750 - val_loss: 0.9788 - val_acc: 0.6900\n",
      "Done training  14000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0422 - acc: 0.6730 - val_loss: 0.9687 - val_acc: 0.7000\n",
      "Done training  15000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0680 - acc: 0.6640 - val_loss: 0.9539 - val_acc: 0.7060\n",
      "Done training  16000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0441 - acc: 0.6810 - val_loss: 0.9452 - val_acc: 0.7110\n",
      "Done training  17000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0832 - acc: 0.6680 - val_loss: 0.9467 - val_acc: 0.7020\n",
      "Done training  18000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0196 - acc: 0.6840 - val_loss: 0.9636 - val_acc: 0.7040\n",
      "Done training  19000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0772 - acc: 0.6680 - val_loss: 0.9485 - val_acc: 0.7100\n",
      "Done training  20000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0247 - acc: 0.6850 - val_loss: 0.9462 - val_acc: 0.7090\n",
      "Done training  21000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1197 - acc: 0.6580 - val_loss: 0.9454 - val_acc: 0.7110\n",
      "Done training  22000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0984 - acc: 0.6690 - val_loss: 0.9436 - val_acc: 0.7070\n",
      "Done training  23000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0524 - acc: 0.6800 - val_loss: 0.9375 - val_acc: 0.7040\n",
      "Done training  24000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0319 - acc: 0.6730 - val_loss: 0.9441 - val_acc: 0.7090\n",
      "Done training  25000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0837 - acc: 0.6690 - val_loss: 0.9416 - val_acc: 0.7150\n",
      "Done training  26000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0886 - acc: 0.6580 - val_loss: 0.9477 - val_acc: 0.7130\n",
      "Done training  27000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0930 - acc: 0.6660 - val_loss: 0.9411 - val_acc: 0.6940\n",
      "Done training  28000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.1258 - acc: 0.6470 - val_loss: 0.9455 - val_acc: 0.6930\n",
      "Done training  29000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0278 - acc: 0.6750 - val_loss: 0.9467 - val_acc: 0.7000\n",
      "Done training  30000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0357 - acc: 0.6990 - val_loss: 0.9484 - val_acc: 0.7060\n",
      "Done training  31000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0884 - acc: 0.6730 - val_loss: 0.9391 - val_acc: 0.7150\n",
      "Done training  32000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 41s 41ms/step - loss: 0.9844 - acc: 0.6950 - val_loss: 0.9433 - val_acc: 0.7030\n",
      "Done training  33000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0532 - acc: 0.6740 - val_loss: 0.9412 - val_acc: 0.6990\n",
      "Done training  34000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0952 - acc: 0.6670 - val_loss: 0.9552 - val_acc: 0.6940\n",
      "Done training  35000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0719 - acc: 0.6790 - val_loss: 0.9543 - val_acc: 0.6970\n",
      "Done training  36000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0931 - acc: 0.6420 - val_loss: 0.9616 - val_acc: 0.6990\n",
      "Done training  37000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0860 - acc: 0.6630 - val_loss: 0.9576 - val_acc: 0.7000\n",
      "Done training  38000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0723 - acc: 0.6750 - val_loss: 0.9712 - val_acc: 0.6970\n",
      "Done training  39000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 40s 40ms/step - loss: 1.0364 - acc: 0.6780 - val_loss: 0.9709 - val_acc: 0.6990\n",
      "Done training  40000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.9997 - acc: 0.6910 - val_loss: 0.9849 - val_acc: 0.6960\n",
      "Done training  41000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 1.0300 - acc: 0.6790 - val_loss: 0.9803 - val_acc: 0.7040\n",
      "Done training  42000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0024 - acc: 0.7040 - val_loss: 0.9866 - val_acc: 0.6920\n",
      "Done training  43000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0299 - acc: 0.6860 - val_loss: 0.9576 - val_acc: 0.6970\n",
      "Done training  44000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9818 - acc: 0.6780 - val_loss: 0.9622 - val_acc: 0.6940\n",
      "Done training  45000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9392 - acc: 0.6900 - val_loss: 0.9531 - val_acc: 0.7010\n",
      "Done training  46000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0380 - acc: 0.6910 - val_loss: 0.9711 - val_acc: 0.6860\n",
      "Done training  47000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.1385 - acc: 0.6450 - val_loss: 0.9590 - val_acc: 0.6980\n",
      "Done training  48000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0088 - acc: 0.7040 - val_loss: 0.9472 - val_acc: 0.6980\n",
      "Done training  49000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0024 - acc: 0.6830 - val_loss: 0.9432 - val_acc: 0.7040\n",
      "Done training  50000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8909 - acc: 0.7270 - val_loss: 0.9367 - val_acc: 0.7090\n",
      "Done training  51000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0496 - acc: 0.6880 - val_loss: 0.9435 - val_acc: 0.7050\n",
      "Done training  52000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0432 - acc: 0.6700 - val_loss: 0.9348 - val_acc: 0.7020\n",
      "Done training  53000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9560 - acc: 0.7050 - val_loss: 0.9498 - val_acc: 0.7080\n",
      "Done training  54000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0162 - acc: 0.6920 - val_loss: 0.9422 - val_acc: 0.6960\n",
      "Done training  55000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9982 - acc: 0.6850 - val_loss: 0.9538 - val_acc: 0.7000\n",
      "Done training  56000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9998 - acc: 0.7000 - val_loss: 0.9659 - val_acc: 0.6910\n",
      "Done training  57000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0616 - acc: 0.6790 - val_loss: 0.9502 - val_acc: 0.7030\n",
      "Done training  58000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0049 - acc: 0.6840 - val_loss: 0.9592 - val_acc: 0.7030\n",
      "Done training  59000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0308 - acc: 0.6910 - val_loss: 0.9486 - val_acc: 0.7010\n",
      "Done training  60000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0458 - acc: 0.6630 - val_loss: 0.9587 - val_acc: 0.6970\n",
      "Done training  61000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0471 - acc: 0.6670 - val_loss: 0.9610 - val_acc: 0.6930\n",
      "Done training  62000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0332 - acc: 0.6850 - val_loss: 0.9715 - val_acc: 0.6870\n",
      "Done training  63000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0852 - acc: 0.6650 - val_loss: 0.9725 - val_acc: 0.6920\n",
      "Done training  64000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0166 - acc: 0.6760 - val_loss: 0.9515 - val_acc: 0.6980\n",
      "Done training  65000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0251 - acc: 0.6730 - val_loss: 0.9429 - val_acc: 0.7040\n",
      "Done training  66000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0283 - acc: 0.6920 - val_loss: 0.9490 - val_acc: 0.6970\n",
      "Done training  67000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0444 - acc: 0.6790 - val_loss: 0.9241 - val_acc: 0.7050\n",
      "Done training  68000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0132 - acc: 0.6830 - val_loss: 0.9161 - val_acc: 0.7030\n",
      "Done training  69000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0336 - acc: 0.6750 - val_loss: 0.9342 - val_acc: 0.7050\n",
      "Done training  70000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0474 - acc: 0.6820 - val_loss: 0.9195 - val_acc: 0.7180\n",
      "Done training  71000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0559 - acc: 0.6690 - val_loss: 0.9257 - val_acc: 0.7150\n",
      "Done training  72000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0182 - acc: 0.6830 - val_loss: 0.9390 - val_acc: 0.7120\n",
      "Done training  73000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0324 - acc: 0.6790 - val_loss: 0.9416 - val_acc: 0.7130\n",
      "Done training  74000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9859 - acc: 0.6860 - val_loss: 0.9141 - val_acc: 0.7000\n",
      "Done training  75000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0558 - acc: 0.6670 - val_loss: 0.9288 - val_acc: 0.7090\n",
      "Done training  76000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0323 - acc: 0.6830 - val_loss: 0.9329 - val_acc: 0.6910\n",
      "Done training  77000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9826 - acc: 0.7030 - val_loss: 0.9420 - val_acc: 0.6950\n",
      "Done training  78000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9706 - acc: 0.6780 - val_loss: 0.9348 - val_acc: 0.6980\n",
      "Done training  79000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0324 - acc: 0.6820 - val_loss: 0.9525 - val_acc: 0.7080\n",
      "Done training  80000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9986 - acc: 0.6990 - val_loss: 0.9586 - val_acc: 0.7020\n",
      "Done training  81000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0257 - acc: 0.6940 - val_loss: 0.9497 - val_acc: 0.7080\n",
      "Done training  82000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9812 - acc: 0.6770 - val_loss: 0.9501 - val_acc: 0.7050\n",
      "Done training  83000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9613 - acc: 0.7130 - val_loss: 0.9377 - val_acc: 0.7100\n",
      "Done training  84000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9010 - acc: 0.7220 - val_loss: 0.9467 - val_acc: 0.7040\n",
      "Done training  85000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0114 - acc: 0.6800 - val_loss: 0.9525 - val_acc: 0.7020\n",
      "Done training  86000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9857 - acc: 0.6960 - val_loss: 0.9547 - val_acc: 0.7060\n",
      "Done training  87000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9991 - acc: 0.6940 - val_loss: 0.9494 - val_acc: 0.7000\n",
      "Done training  88000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0166 - acc: 0.6870 - val_loss: 0.9562 - val_acc: 0.7060\n",
      "Done training  89000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0407 - acc: 0.6870 - val_loss: 0.9458 - val_acc: 0.7120\n",
      "Done training  90000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0398 - acc: 0.6950 - val_loss: 0.9389 - val_acc: 0.7060\n",
      "Done training  91000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0088 - acc: 0.6960 - val_loss: 0.9316 - val_acc: 0.7040\n",
      "Done training  92000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0024 - acc: 0.6670 - val_loss: 0.9471 - val_acc: 0.7050\n",
      "Done training  93000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9459 - acc: 0.7060 - val_loss: 0.9488 - val_acc: 0.7010\n",
      "Done training  94000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9672 - acc: 0.6840 - val_loss: 0.9206 - val_acc: 0.7030\n",
      "Done training  95000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9790 - acc: 0.6890 - val_loss: 0.9330 - val_acc: 0.7110\n",
      "Done training  96000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0071 - acc: 0.7020 - val_loss: 0.9544 - val_acc: 0.7100\n",
      "Done training  97000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9338 - acc: 0.7030 - val_loss: 0.9556 - val_acc: 0.7110\n",
      "Done training  98000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9338 - acc: 0.6930 - val_loss: 0.9300 - val_acc: 0.7180\n",
      "Done training  99000  images in Epoch :  2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0462 - acc: 0.6790 - val_loss: 0.9344 - val_acc: 0.7150\n",
      "Done training  100000  images in Epoch :  2\n",
      "Done training 100000 images, Epoch  2   -------------\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0370 - acc: 0.6760 - val_loss: 0.9355 - val_acc: 0.7150\n",
      "Done training  1000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0099 - acc: 0.6850 - val_loss: 0.9457 - val_acc: 0.7040\n",
      "Done training  2000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9429 - acc: 0.6880 - val_loss: 0.9447 - val_acc: 0.7140\n",
      "Done training  3000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9917 - acc: 0.6700 - val_loss: 0.9595 - val_acc: 0.7090\n",
      "Done training  4000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9767 - acc: 0.6890 - val_loss: 0.9570 - val_acc: 0.6990\n",
      "Done training  5000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9332 - acc: 0.7030 - val_loss: 0.9629 - val_acc: 0.6980\n",
      "Done training  6000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9040 - acc: 0.7070 - val_loss: 0.9402 - val_acc: 0.7020\n",
      "Done training  7000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 1.0084 - acc: 0.6830 - val_loss: 0.9362 - val_acc: 0.7090\n",
      "Done training  8000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9942 - acc: 0.6910 - val_loss: 0.9369 - val_acc: 0.6990\n",
      "Done training  9000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9423 - acc: 0.6840 - val_loss: 0.9410 - val_acc: 0.6980\n",
      "Done training  10000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9628 - acc: 0.7030 - val_loss: 0.9494 - val_acc: 0.7080\n",
      "Done training  11000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9611 - acc: 0.7140 - val_loss: 0.9736 - val_acc: 0.7050\n",
      "Done training  12000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9341 - acc: 0.6990 - val_loss: 0.9790 - val_acc: 0.7010\n",
      "Done training  13000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9690 - acc: 0.7010 - val_loss: 0.9665 - val_acc: 0.6960\n",
      "Done training  14000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9738 - acc: 0.7060 - val_loss: 0.9612 - val_acc: 0.6990\n",
      "Done training  15000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8959 - acc: 0.7190 - val_loss: 0.9589 - val_acc: 0.6960\n",
      "Done training  16000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8772 - acc: 0.7220 - val_loss: 0.9527 - val_acc: 0.6990\n",
      "Done training  17000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9123 - acc: 0.7070 - val_loss: 0.9687 - val_acc: 0.7020\n",
      "Done training  18000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8750 - acc: 0.7230 - val_loss: 0.9762 - val_acc: 0.7070\n",
      "Done training  19000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9576 - acc: 0.7010 - val_loss: 0.9584 - val_acc: 0.7030\n",
      "Done training  20000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9332 - acc: 0.6990 - val_loss: 0.9552 - val_acc: 0.7040\n",
      "Done training  21000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9939 - acc: 0.6950 - val_loss: 0.9518 - val_acc: 0.7020\n",
      "Done training  22000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9685 - acc: 0.6770 - val_loss: 0.9503 - val_acc: 0.7110\n",
      "Done training  23000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9201 - acc: 0.7060 - val_loss: 0.9350 - val_acc: 0.7170\n",
      "Done training  24000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9547 - acc: 0.6700 - val_loss: 0.9195 - val_acc: 0.7100\n",
      "Done training  25000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8921 - acc: 0.7100 - val_loss: 0.9339 - val_acc: 0.7190\n",
      "Done training  26000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9270 - acc: 0.6900 - val_loss: 0.9392 - val_acc: 0.7110\n",
      "Done training  27000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9709 - acc: 0.6910 - val_loss: 0.9502 - val_acc: 0.7000\n",
      "Done training  28000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9482 - acc: 0.7000 - val_loss: 0.9548 - val_acc: 0.7050\n",
      "Done training  29000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9818 - acc: 0.6850 - val_loss: 0.9570 - val_acc: 0.7080\n",
      "Done training  30000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9567 - acc: 0.7030 - val_loss: 0.9660 - val_acc: 0.7000\n",
      "Done training  31000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9429 - acc: 0.6990 - val_loss: 0.9570 - val_acc: 0.6960\n",
      "Done training  32000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9349 - acc: 0.7000 - val_loss: 0.9673 - val_acc: 0.7070\n",
      "Done training  33000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9601 - acc: 0.7000 - val_loss: 0.9733 - val_acc: 0.7030\n",
      "Done training  34000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9089 - acc: 0.7240 - val_loss: 0.9793 - val_acc: 0.6980\n",
      "Done training  35000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9340 - acc: 0.7020 - val_loss: 0.9612 - val_acc: 0.7020\n",
      "Done training  36000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8975 - acc: 0.7220 - val_loss: 0.9805 - val_acc: 0.7090\n",
      "Done training  37000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8907 - acc: 0.7000 - val_loss: 0.9844 - val_acc: 0.7070\n",
      "Done training  38000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9551 - acc: 0.7170 - val_loss: 0.9817 - val_acc: 0.6960\n",
      "Done training  39000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8626 - acc: 0.7270 - val_loss: 0.9686 - val_acc: 0.7040\n",
      "Done training  40000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8710 - acc: 0.7160 - val_loss: 0.9759 - val_acc: 0.6920\n",
      "Done training  41000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8560 - acc: 0.7270 - val_loss: 0.9809 - val_acc: 0.7010\n",
      "Done training  42000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8610 - acc: 0.7300 - val_loss: 0.9792 - val_acc: 0.7000\n",
      "Done training  43000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8504 - acc: 0.7090 - val_loss: 0.9945 - val_acc: 0.6930\n",
      "Done training  44000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8909 - acc: 0.7000 - val_loss: 1.0033 - val_acc: 0.6950\n",
      "Done training  45000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8817 - acc: 0.7220 - val_loss: 0.9961 - val_acc: 0.7100\n",
      "Done training  46000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8057 - acc: 0.7350 - val_loss: 1.0016 - val_acc: 0.7060\n",
      "Done training  47000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8918 - acc: 0.7220 - val_loss: 0.9900 - val_acc: 0.7100\n",
      "Done training  48000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8683 - acc: 0.7140 - val_loss: 0.9771 - val_acc: 0.7130\n",
      "Done training  49000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8341 - acc: 0.7280 - val_loss: 0.9721 - val_acc: 0.7130\n",
      "Done training  50000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8104 - acc: 0.7530 - val_loss: 0.9827 - val_acc: 0.7170\n",
      "Done training  51000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8907 - acc: 0.7140 - val_loss: 0.9749 - val_acc: 0.7090\n",
      "Done training  52000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8214 - acc: 0.7210 - val_loss: 0.9700 - val_acc: 0.7210\n",
      "Done training  53000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8884 - acc: 0.7500 - val_loss: 0.9839 - val_acc: 0.7150\n",
      "Done training  54000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9376 - acc: 0.7100 - val_loss: 0.9768 - val_acc: 0.7110\n",
      "Done training  55000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8607 - acc: 0.7360 - val_loss: 0.9872 - val_acc: 0.7050\n",
      "Done training  56000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8027 - acc: 0.7510 - val_loss: 0.9876 - val_acc: 0.7140\n",
      "Done training  57000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9498 - acc: 0.7090 - val_loss: 0.9761 - val_acc: 0.7090\n",
      "Done training  58000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8810 - acc: 0.7200 - val_loss: 0.9669 - val_acc: 0.7120\n",
      "Done training  59000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8471 - acc: 0.7350 - val_loss: 0.9574 - val_acc: 0.7150\n",
      "Done training  60000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9158 - acc: 0.6920 - val_loss: 0.9275 - val_acc: 0.7080\n",
      "Done training  61000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9202 - acc: 0.7050 - val_loss: 0.9246 - val_acc: 0.7090\n",
      "Done training  62000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9015 - acc: 0.7140 - val_loss: 0.9216 - val_acc: 0.7120\n",
      "Done training  63000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9360 - acc: 0.7100 - val_loss: 0.9389 - val_acc: 0.7190\n",
      "Done training  64000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8607 - acc: 0.7300 - val_loss: 0.9381 - val_acc: 0.7190\n",
      "Done training  65000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8919 - acc: 0.7170 - val_loss: 0.9499 - val_acc: 0.7120\n",
      "Done training  66000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8484 - acc: 0.7310 - val_loss: 0.9537 - val_acc: 0.7140\n",
      "Done training  67000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8761 - acc: 0.7230 - val_loss: 0.9302 - val_acc: 0.7180\n",
      "Done training  68000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9449 - acc: 0.7060 - val_loss: 0.9083 - val_acc: 0.7240\n",
      "Done training  69000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8822 - acc: 0.7040 - val_loss: 0.9274 - val_acc: 0.7180\n",
      "Done training  70000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8726 - acc: 0.7190 - val_loss: 0.9102 - val_acc: 0.7230\n",
      "Done training  71000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.9439 - acc: 0.7080 - val_loss: 0.9017 - val_acc: 0.7170\n",
      "Done training  72000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9264 - acc: 0.6980 - val_loss: 0.9060 - val_acc: 0.7230\n",
      "Done training  73000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9469 - acc: 0.6990 - val_loss: 0.9177 - val_acc: 0.7180\n",
      "Done training  74000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8368 - acc: 0.7150 - val_loss: 0.9292 - val_acc: 0.7200\n",
      "Done training  75000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9058 - acc: 0.7080 - val_loss: 0.9224 - val_acc: 0.7170\n",
      "Done training  76000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9048 - acc: 0.7090 - val_loss: 0.9372 - val_acc: 0.7100\n",
      "Done training  77000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8684 - acc: 0.7220 - val_loss: 0.9439 - val_acc: 0.7060\n",
      "Done training  78000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9331 - acc: 0.7020 - val_loss: 0.9401 - val_acc: 0.7150\n",
      "Done training  79000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8381 - acc: 0.7390 - val_loss: 0.9533 - val_acc: 0.7060\n",
      "Done training  80000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8741 - acc: 0.7170 - val_loss: 0.9434 - val_acc: 0.7130\n",
      "Done training  81000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9083 - acc: 0.7090 - val_loss: 0.9480 - val_acc: 0.7150\n",
      "Done training  82000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9285 - acc: 0.7050 - val_loss: 0.9378 - val_acc: 0.7150\n",
      "Done training  83000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9306 - acc: 0.7090 - val_loss: 0.9371 - val_acc: 0.7050\n",
      "Done training  84000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8151 - acc: 0.7380 - val_loss: 0.9432 - val_acc: 0.7190\n",
      "Done training  85000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8106 - acc: 0.7370 - val_loss: 0.9569 - val_acc: 0.7110\n",
      "Done training  86000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9237 - acc: 0.7040 - val_loss: 0.9398 - val_acc: 0.7200\n",
      "Done training  87000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8666 - acc: 0.7210 - val_loss: 0.9116 - val_acc: 0.7290\n",
      "Done training  88000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8804 - acc: 0.7070 - val_loss: 0.9442 - val_acc: 0.7190\n",
      "Done training  89000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8008 - acc: 0.7390 - val_loss: 0.9635 - val_acc: 0.7140\n",
      "Done training  90000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.9052 - acc: 0.7070 - val_loss: 0.9452 - val_acc: 0.7090\n",
      "Done training  91000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8567 - acc: 0.7360 - val_loss: 0.9284 - val_acc: 0.7140\n",
      "Done training  92000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8848 - acc: 0.7200 - val_loss: 0.9422 - val_acc: 0.7110\n",
      "Done training  93000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7607 - acc: 0.7550 - val_loss: 0.9460 - val_acc: 0.7080\n",
      "Done training  94000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8581 - acc: 0.7250 - val_loss: 0.9527 - val_acc: 0.7040\n",
      "Done training  95000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7880 - acc: 0.7540 - val_loss: 0.9616 - val_acc: 0.7150\n",
      "Done training  96000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8367 - acc: 0.7460 - val_loss: 0.9602 - val_acc: 0.7180\n",
      "Done training  97000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8520 - acc: 0.7430 - val_loss: 0.9632 - val_acc: 0.7230\n",
      "Done training  98000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7956 - acc: 0.7330 - val_loss: 0.9786 - val_acc: 0.7130\n",
      "Done training  99000  images in Epoch :  3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8352 - acc: 0.7270 - val_loss: 0.9648 - val_acc: 0.7110\n",
      "Done training  100000  images in Epoch :  3\n",
      "Done training 100000 images, Epoch  3   -------------\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8689 - acc: 0.7300 - val_loss: 0.9793 - val_acc: 0.7070\n",
      "Done training  1000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8267 - acc: 0.7320 - val_loss: 0.9724 - val_acc: 0.7060\n",
      "Done training  2000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8419 - acc: 0.7180 - val_loss: 0.9537 - val_acc: 0.7180\n",
      "Done training  3000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8226 - acc: 0.7310 - val_loss: 0.9698 - val_acc: 0.7200\n",
      "Done training  4000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8994 - acc: 0.7150 - val_loss: 0.9626 - val_acc: 0.7060\n",
      "Done training  5000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8351 - acc: 0.7460 - val_loss: 0.9500 - val_acc: 0.7120\n",
      "Done training  6000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.7991 - acc: 0.7390 - val_loss: 0.9549 - val_acc: 0.7130\n",
      "Done training  7000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8821 - acc: 0.7130 - val_loss: 0.9452 - val_acc: 0.7090\n",
      "Done training  8000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8616 - acc: 0.7240 - val_loss: 0.9318 - val_acc: 0.7110\n",
      "Done training  9000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8402 - acc: 0.7300 - val_loss: 0.9395 - val_acc: 0.7060\n",
      "Done training  10000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8028 - acc: 0.7370 - val_loss: 0.9307 - val_acc: 0.7190\n",
      "Done training  11000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7643 - acc: 0.7580 - val_loss: 0.9314 - val_acc: 0.7190\n",
      "Done training  12000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8006 - acc: 0.7590 - val_loss: 0.9514 - val_acc: 0.7120\n",
      "Done training  13000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7793 - acc: 0.7390 - val_loss: 0.9732 - val_acc: 0.7150\n",
      "Done training  14000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7944 - acc: 0.7290 - val_loss: 0.9816 - val_acc: 0.7130\n",
      "Done training  15000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7738 - acc: 0.7360 - val_loss: 0.9560 - val_acc: 0.7210\n",
      "Done training  16000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8029 - acc: 0.7340 - val_loss: 0.9429 - val_acc: 0.7210\n",
      "Done training  17000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7294 - acc: 0.7500 - val_loss: 0.9500 - val_acc: 0.7170\n",
      "Done training  18000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7471 - acc: 0.7520 - val_loss: 0.9303 - val_acc: 0.7120\n",
      "Done training  19000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8215 - acc: 0.7230 - val_loss: 0.9255 - val_acc: 0.7200\n",
      "Done training  20000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7806 - acc: 0.7530 - val_loss: 0.9366 - val_acc: 0.7070\n",
      "Done training  21000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8644 - acc: 0.7090 - val_loss: 0.9384 - val_acc: 0.7070\n",
      "Done training  22000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8399 - acc: 0.7220 - val_loss: 0.9271 - val_acc: 0.7050\n",
      "Done training  23000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7984 - acc: 0.7370 - val_loss: 0.9421 - val_acc: 0.7010\n",
      "Done training  24000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8181 - acc: 0.7400 - val_loss: 0.9572 - val_acc: 0.7110\n",
      "Done training  25000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8265 - acc: 0.7270 - val_loss: 0.9466 - val_acc: 0.7080\n",
      "Done training  26000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8056 - acc: 0.7240 - val_loss: 0.9637 - val_acc: 0.7110\n",
      "Done training  27000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8274 - acc: 0.7300 - val_loss: 0.9532 - val_acc: 0.7140\n",
      "Done training  28000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7886 - acc: 0.7350 - val_loss: 0.9567 - val_acc: 0.7080\n",
      "Done training  29000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7951 - acc: 0.7400 - val_loss: 0.9642 - val_acc: 0.7160\n",
      "Done training  30000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 39s 39ms/step - loss: 0.8182 - acc: 0.7330 - val_loss: 0.9822 - val_acc: 0.7120\n",
      "Done training  31000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8566 - acc: 0.7150 - val_loss: 0.9861 - val_acc: 0.6960\n",
      "Done training  32000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7649 - acc: 0.7490 - val_loss: 0.9748 - val_acc: 0.7150\n",
      "Done training  33000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8043 - acc: 0.7340 - val_loss: 0.9988 - val_acc: 0.7100\n",
      "Done training  34000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8312 - acc: 0.7340 - val_loss: 1.0038 - val_acc: 0.7030\n",
      "Done training  35000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7731 - acc: 0.7430 - val_loss: 0.9758 - val_acc: 0.7040\n",
      "Done training  36000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8609 - acc: 0.7140 - val_loss: 0.9657 - val_acc: 0.7110\n",
      "Done training  37000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8373 - acc: 0.7180 - val_loss: 0.9784 - val_acc: 0.7010\n",
      "Done training  38000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8074 - acc: 0.7400 - val_loss: 0.9957 - val_acc: 0.6900\n",
      "Done training  39000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7838 - acc: 0.7350 - val_loss: 0.9936 - val_acc: 0.7090\n",
      "Done training  40000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7407 - acc: 0.7570 - val_loss: 1.0079 - val_acc: 0.6940\n",
      "Done training  41000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7332 - acc: 0.7530 - val_loss: 1.0124 - val_acc: 0.7000\n",
      "Done training  42000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7329 - acc: 0.7580 - val_loss: 1.0141 - val_acc: 0.7050\n",
      "Done training  43000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7723 - acc: 0.7570 - val_loss: 1.0216 - val_acc: 0.7060\n",
      "Done training  44000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.6893 - acc: 0.7760 - val_loss: 1.0418 - val_acc: 0.7040\n",
      "Done training  45000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7472 - acc: 0.7570 - val_loss: 1.0295 - val_acc: 0.7050\n",
      "Done training  46000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8231 - acc: 0.7400 - val_loss: 1.0423 - val_acc: 0.7060\n",
      "Done training  47000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8175 - acc: 0.7320 - val_loss: 0.9967 - val_acc: 0.7190\n",
      "Done training  48000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7839 - acc: 0.7470 - val_loss: 1.0262 - val_acc: 0.6930\n",
      "Done training  49000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7570 - acc: 0.7410 - val_loss: 1.0168 - val_acc: 0.6900\n",
      "Done training  50000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7488 - acc: 0.7710 - val_loss: 1.0043 - val_acc: 0.7050\n",
      "Done training  51000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7552 - acc: 0.7670 - val_loss: 0.9952 - val_acc: 0.7100\n",
      "Done training  52000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7259 - acc: 0.7670 - val_loss: 0.9893 - val_acc: 0.7140\n",
      "Done training  53000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7656 - acc: 0.7650 - val_loss: 0.9815 - val_acc: 0.7200\n",
      "Done training  54000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7884 - acc: 0.7560 - val_loss: 1.0105 - val_acc: 0.7170\n",
      "Done training  55000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7488 - acc: 0.7350 - val_loss: 0.9881 - val_acc: 0.7190\n",
      "Done training  56000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7212 - acc: 0.7630 - val_loss: 1.0267 - val_acc: 0.7110\n",
      "Done training  57000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7467 - acc: 0.7730 - val_loss: 1.0111 - val_acc: 0.7110\n",
      "Done training  58000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7432 - acc: 0.7530 - val_loss: 1.0253 - val_acc: 0.7100\n",
      "Done training  59000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7304 - acc: 0.7640 - val_loss: 1.0122 - val_acc: 0.7190\n",
      "Done training  60000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7830 - acc: 0.7460 - val_loss: 1.0003 - val_acc: 0.7100\n",
      "Done training  61000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8684 - acc: 0.7280 - val_loss: 1.0002 - val_acc: 0.7060\n",
      "Done training  62000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7375 - acc: 0.7670 - val_loss: 0.9794 - val_acc: 0.7060\n",
      "Done training  63000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7499 - acc: 0.7460 - val_loss: 0.9777 - val_acc: 0.7010\n",
      "Done training  64000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7485 - acc: 0.7470 - val_loss: 0.9778 - val_acc: 0.7050\n",
      "Done training  65000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7097 - acc: 0.7660 - val_loss: 0.9912 - val_acc: 0.7040\n",
      "Done training  66000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7986 - acc: 0.7470 - val_loss: 0.9959 - val_acc: 0.7070\n",
      "Done training  67000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7846 - acc: 0.7320 - val_loss: 0.9936 - val_acc: 0.7070\n",
      "Done training  68000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8023 - acc: 0.7380 - val_loss: 0.9689 - val_acc: 0.7030\n",
      "Done training  69000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.6986 - acc: 0.7640 - val_loss: 0.9752 - val_acc: 0.7070\n",
      "Done training  70000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7890 - acc: 0.7300 - val_loss: 0.9917 - val_acc: 0.7130\n",
      "Done training  71000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7442 - acc: 0.7510 - val_loss: 0.9652 - val_acc: 0.7050\n",
      "Done training  72000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7739 - acc: 0.7430 - val_loss: 0.9693 - val_acc: 0.7130\n",
      "Done training  73000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8182 - acc: 0.7190 - val_loss: 0.9630 - val_acc: 0.6990\n",
      "Done training  74000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7444 - acc: 0.7540 - val_loss: 0.9743 - val_acc: 0.7020\n",
      "Done training  75000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7841 - acc: 0.7460 - val_loss: 0.9670 - val_acc: 0.7030\n",
      "Done training  76000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7260 - acc: 0.7610 - val_loss: 0.9719 - val_acc: 0.6990\n",
      "Done training  77000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7100 - acc: 0.7600 - val_loss: 0.9708 - val_acc: 0.7040\n",
      "Done training  78000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.8089 - acc: 0.7470 - val_loss: 0.9615 - val_acc: 0.7110\n",
      "Done training  79000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7183 - acc: 0.7560 - val_loss: 0.9773 - val_acc: 0.7120\n",
      "Done training  80000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7579 - acc: 0.7640 - val_loss: 0.9642 - val_acc: 0.7040\n",
      "Done training  81000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7242 - acc: 0.7690 - val_loss: 0.9866 - val_acc: 0.7070\n",
      "Done training  82000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7607 - acc: 0.7470 - val_loss: 0.9905 - val_acc: 0.7140\n",
      "Done training  83000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7443 - acc: 0.7670 - val_loss: 1.0069 - val_acc: 0.7070\n",
      "Done training  84000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7430 - acc: 0.7480 - val_loss: 1.0351 - val_acc: 0.7080\n",
      "Done training  85000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7535 - acc: 0.7540 - val_loss: 0.9997 - val_acc: 0.7200\n",
      "Done training  86000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7630 - acc: 0.7560 - val_loss: 0.9789 - val_acc: 0.7020\n",
      "Done training  87000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7198 - acc: 0.7650 - val_loss: 0.9622 - val_acc: 0.7070\n",
      "Done training  88000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7488 - acc: 0.7400 - val_loss: 0.9741 - val_acc: 0.7120\n",
      "Done training  89000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7157 - acc: 0.7580 - val_loss: 0.9835 - val_acc: 0.6990\n",
      "Done training  90000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7808 - acc: 0.7310 - val_loss: 0.9886 - val_acc: 0.7000\n",
      "Done training  91000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7692 - acc: 0.7480 - val_loss: 0.9709 - val_acc: 0.7020\n",
      "Done training  92000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7549 - acc: 0.7370 - val_loss: 0.9813 - val_acc: 0.7020\n",
      "Done training  93000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.6888 - acc: 0.7690 - val_loss: 0.9837 - val_acc: 0.6890\n",
      "Done training  94000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7240 - acc: 0.7650 - val_loss: 0.9696 - val_acc: 0.7030\n",
      "Done training  95000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7486 - acc: 0.7650 - val_loss: 0.9840 - val_acc: 0.6950\n",
      "Done training  96000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7259 - acc: 0.7550 - val_loss: 0.9939 - val_acc: 0.7010\n",
      "Done training  97000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7196 - acc: 0.7710 - val_loss: 0.9922 - val_acc: 0.7080\n",
      "Done training  98000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7727 - acc: 0.7530 - val_loss: 0.9935 - val_acc: 0.7030\n",
      "Done training  99000  images in Epoch :  4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 38s 38ms/step - loss: 0.7690 - acc: 0.7360 - val_loss: 0.9701 - val_acc: 0.7030\n",
      "Done training  100000  images in Epoch :  4\n",
      "Done training 100000 images, Epoch  4   -------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):#5\n",
    "    for j in range(100):#100,000100\n",
    "        X = np.load( \"C:/Users/firzen41616316/Desktop/numpydataKeras/imgonehot_\"+str((j+1)*1000)+\".npy\" )\n",
    "        Y = np.load( \"C:/Users/firzen41616316/Desktop/numpydataKeras/labelonehot_\"+str((j+1)*1000)+\".npy\" )\n",
    "        net_final.fit(x = X, y = Y,\n",
    "                      epochs = 1,#\n",
    "                      validation_data=(V1, V2),\n",
    "                      verbose = 1)#12epoch\n",
    "        print('Done training ', (j+1)*1000 ,' images in Epoch : ', i)\n",
    "    print('Done training 100000 images, Epoch ', i ,'  -------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Succeed--------------\n"
     ]
    }
   ],
   "source": [
    "#  HDF5 \n",
    "net_final.save('C:/Users/firzen41616316/Desktop/transfer_learning_DenseNet121_02.h5')\n",
    "print('Saved Succeed--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top-1top-3 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from time import time\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "import keras\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "model = load_model('C:/Users/cloudadavncenew0709/Desktop/transfer_learning_DenseNet121_02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_acc = functools.partial(keras.metrics.top_k_categorical_accuracy, k=3)\n",
    "\n",
    "top3_acc.__name__ = 'top3_acc'\n",
    "\n",
    "model.compile(Adam(lr=.00002122), loss='categorical_crossentropy', metrics = ['accuracy', top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "V1 = np.load(\"C:/Users/cloudadavncenew0709/Desktop/numpydataKeras_20_val/imgonehot_val_1000.npy\")\n",
    "V2 = np.load(\"C:/Users/cloudadavncenew0709/Desktop/numpydataKeras_20_val/labelonehot_val_1000.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 37s 37ms/step - loss: 0.7228 - acc: 0.7650 - top3_acc: 0.9350 - val_loss: 0.9701 - val_acc: 0.7030 - val_top3_acc: 0.9150\n",
      "Done training  1000  images in Epoch :  0\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      " 992/1000 [============================>.] - ETA: 0s - loss: 0.7345 - acc: 0.7520 - top3_acc: 0.9345"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-3edc24ec02ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                       \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mV1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                       verbose = 1)#12epoch\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done training '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1000\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m' images in Epoch : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done training 100000 images, Epoch '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m'  -------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras35\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[0;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m                                              verbose=0)\n\u001b[0m\u001b[0;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                         \u001b[1;31m# Same labels assumed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras35\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):#5\n",
    "    for j in range(100):#100,000100\n",
    "        X = np.load( \"C:/Users/cloudadavncenew0709/Desktop/numpydataKeras/imgonehot_\"+str((j+1)*1000)+\".npy\" )\n",
    "        Y = np.load( \"C:/Users/cloudadavncenew0709/Desktop/numpydataKeras/labelonehot_\"+str((j+1)*1000)+\".npy\" )\n",
    "        model.fit(x = X, y = Y,\n",
    "                      epochs = 1,#\n",
    "                      validation_data=(V1, V2),\n",
    "                      verbose = 1)#12epoch\n",
    "        print('Done training ', (j+1)*1000 ,' images in Epoch : ', i)\n",
    "    print('Done training 100000 images, Epoch ', i ,'  -------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
